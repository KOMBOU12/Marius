{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOMBOU12/Marius/blob/main/Projet5_FC_LRP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Tâche 1 : LRP appliqué à un réseau de neurones entièrement connecté (FC)**\n",
        "\n",
        "Dans cette tâche, l'objectif est de calculer la pertinence (relevance) pour des éléments spécifiques d'un petit réseau de neurones entièrement connecté. Le réseau est composé uniquement d'une couche d'entrée (ses neurones sont indexés par ($i$),d'une couche cachée ($j$) et d'une couche de sortie ($k$). $x_i$ représente les valeurs des neurones d'entrée, $x_j$ les sorties des neurones de la couche cachée, et $x_k$ les sorties des neurones de la couche de sortie. La fonction non linéaire de la couche cachée est la ReLU, exprimée par l'équation\n",
        "$x_j = max(0, \\sum_i x_i w_{ij} + b_j)$. $w_{ij}\\:$ désigne les poids entre la  $i-$ième et la $j-$ième couche, et $b_j$ le biais (ce dernier est omis dans cette tâche). La fonction non linéaire effectuée par la couche de sortie est la fonction de somme, exprimée par $x_k = \\sum_j x_j$.L'architecture globale du réseau est illustrée dans la première figure, et le fonctionnement de chaque neurone est décrit dans la deuxième.\n",
        "\n",
        "Cette tâche n'utilise pas de jeu de données prédéfini. Les utilisateurs sélectionneront les entrées du réseau de neurones ainsi que les poids. Nous encourageons les utilisateurs à essayer autant de combinaisons possibles d'entrées et de poids. La méthode LRP sera appliquée pour calculer la pertinence de chaque neurone et des entrées.\n"
      ],
      "metadata": {
        "id": "AQE0WxSzgBp4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoaO8nmKZqK6",
        "outputId": "89839303-1468-405f-b63a-8fa26e76c2fb"
      },
      "source": [
        "################################################################################\n",
        "# [0.] Installation of the necessary packages ==================================\n",
        "################################################################################\n",
        "\n",
        "!pip3 install scipy\n",
        "!pip3 install matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "4734d8c4-9d85-4c7d-ba52-4129578b6f9e",
        "id": "0ptGS70airut"
      },
      "source": [
        "################################################################################\n",
        "# Figure of the overall architecture of the FC network =========================\n",
        "################################################################################\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/figures/FC_Neural_Network_A.png\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_A.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_A.png'"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_A.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_A.png'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "NLQzmta-bZDZ",
        "outputId": "6f29b9e1-0d5e-40aa-9f99-da8fd91ee8cd"
      },
      "source": [
        "################################################################################\n",
        "# Figure of the functionality of one neuron - the one of the output layer, =====\n",
        "# but can be extended to all neurons without loss of generality ================\n",
        "################################################################################\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/figures/FC_Neural_Network_B.jpeg\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_B.jpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_B.jpeg'"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_B.jpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/content/drive/MyDrive/figures/FC_Neural_Network_B.jpeg'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "jd5sjFJldeRd",
        "outputId": "d83e1038-db4a-4c29-eadf-70fba0b0b3d4"
      },
      "source": [
        "################################################################################\n",
        "# Mathematical euqations for the computation of relevances (R) =================\n",
        "# in the output (k), hidden (j) and input (i) layer. ===========================\n",
        "################################################################################\n",
        "from IPython.display import Math, HTML\n",
        "\n",
        "# The output layer's (k) output is the sum of the all inputs x_j ---------------\n",
        "# The relevance R_k of the neuron in this layer --------------------------------\n",
        "# is also the sum of all its inputs --------------------------------------------\n",
        "\n",
        "# The output x_j of each neuron in layer (j) -----------------------------------\n",
        "# (each of them is subscripted with j) -----------------------------------------\n",
        "# is either zero or equals to the sum of the weighted inputs -------------------\n",
        "# plus the bias term -----------------------------------------------------------\n",
        "\n",
        "Math(r'x_j = max(0, \\sum_i x_i w_{ij} + b_j) \\\\ R_k = x_k = \\sum_j x_j \\\\ ')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle x_j = max(0, \\sum_i x_i w_{ij} + b_j) \\\\ R_k = x_k = \\sum_j x_j \\\\ $"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "id": "v9F1Cx8ZbfOc",
        "outputId": "7e4575d9-7309-4882-e1be-093d9b92e83e"
      },
      "source": [
        "# The relevance of each neuron j in layer (j) is R_j. --------------------------\n",
        "# This can be deduced from the equation that computes x_j ----------------------\n",
        "# and by the observation that the root point (x_tilde) equals to zero. ---------\n",
        "\n",
        "from IPython.display import Math\n",
        "\n",
        "Math(r'R_j = R_k(\\tilde{\\mathbf{x}}) + \\frac{\\partial R_k}{\\partial x_j} \\biggr\\rvert_{\\{ \\tilde{x}_j \\}} \\cdot (x_j - \\tilde{x}_j) = x_j = max(0, \\sum_i x_i w_{ij} + b_j) \\\\' )\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle R_j = R_k(\\tilde{\\mathbf{x}}) + \\frac{\\partial R_k}{\\partial x_j} \\biggr\\rvert_{\\{ \\tilde{x}_j \\}} \\cdot (x_j - \\tilde{x}_j) = x_j = max(0, \\sum_i x_i w_{ij} + b_j) \\\\$"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cAzP-lvjiUtR",
        "outputId": "ee6797a8-5b13-4eb3-8687-9122d5558a8d"
      },
      "source": [
        "# The relevance of each neuron i in layer (i), which is practically the input --\n",
        "# is R_i. The mathematical equations behind this computation -------------------\n",
        "# can be found in the referenced sources and are out of scope of this ----------\n",
        "# task. What is important to emphasize is that the relevance is proportional ---\n",
        "# to the power of the weights - remember that the weights can be ---------------\n",
        "# positive and negative --------------------------------------------------------\n",
        "\n",
        "from IPython.display import Math\n",
        "\n",
        "Math(r'R_i = \\sum_j \\frac{w_{ij}^2}{\\sum_{\\'{i}}} w_{\\acute{\\'{i}}j}^2} R_j')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle R_i = \\sum_j \\frac{w_{ij}^2}{\\sum_{\\'{i}}} w_{\\acute{\\'{i}}j}^2} R_j$"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "💻 Dans ce code, le réseau de neurones se compose des couches suivantes :\n",
        "\n",
        "📌 La **couche d'entrée** est définie par les variables dans `x_i_dict`, qui contient 3 neurones\n",
        "\n",
        "📌 La **couche cachée** est composée de 5 neurones (`w_j_1_dict, w_j_2_dict, w_j_3_dict, w_j_4_dict, w_j_5_dict`), comme en témoignent les dictionnaires définis pour chaque ensemble de poids reliant les entrées $(x_i)$ aux neurones cachés $(x_j)$\n",
        "\n",
        "📌 La **couche de sortie** est définie par les poids `w_k_dict`, qui relient les 5 neurones de la couche cachée $(x_j)$  à un seul neurone de sortie $(x_k)$\n",
        "\n",
        "Ce réseau est  un exemple de réseau entièrement connecté avec une architecture de type 3 → 5 → 1.\n",
        "\n",
        "💡 Le dictionnaire `w_j_1_dict = {'w_i1_j1': -0.2, 'w_i2_j1': 0.5, 'w_i3_j1': -0.1}`  représente les poids connectant chaque neurone de la couche d'entrée à un neurone spécifique de la couche cachée.\n",
        "\n",
        "\n",
        "*   w_i1_j1: Poids entre le neurone $x_1$ (entrée) et $x_{j1}$ (caché)\n",
        "*   w_i2_j1: Poids entre le neurone $x_2$ (entrée) et $x_{j1}$ (caché)\n",
        "*   w_i3_j1: Poids entre le neurone $x_3$ (entrée) et $x_{j1}$ (caché)\n",
        "\n",
        "\n",
        "# Formule réelle pour calculer $x_j$\n",
        "\n",
        "Les poids influencent la manière dont les informations de la couche d'entrée sont combinées dans la couche cachée. Chaque neurone caché $(x_{j1}, x_{j2}, x_{j3})$ calcule une somme pondérée des entrées suivant la **formule** : $x_j = \\text{ReLU}\\left(\\sum_{i} x_i \\cdot w_{ij} + b_j\\right)$.\n",
        "\n",
        "🔍 Par exemple avec les poids définis dans `w_j_1_dict` et les valeurs d'entrée $(x_1 = 2, x_2 = 5, x_3 = 50)$\n",
        "$$\n",
        "x_{j1} = \\text{ReLU}\\left(x_1 \\cdot (-0.2) + x_2 \\cdot 0.5 + x_3 \\cdot (-0.1)\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "x_{j1} = \\text{ReLU}\\left((2) \\cdot (-0.2) + (5) \\cdot 0.5 + (50) \\cdot (-0.1)\\right)\n",
        "$$\n",
        "Cette formule n'est pas utilisé dans ce code.\n",
        "\n",
        "# Différence dans ce code\n",
        "\n",
        "`x_j_1_normal`, `x_j_2_normal`, ..etc sont générés aléatoirement, suivant une distribution de notre choix et n'ont aucune dépendance aux poids ou entrées définis dans le réseau."
      ],
      "metadata": {
        "id": "AwK4gh1C6fOH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0titLqrsj0ZS",
        "outputId": "387e182d-d687-4aa4-cf66-8b3f4c25bb46"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "################################################################################\n",
        "# [1.] Define input, weights ===================================================\n",
        "#      and see their distribution with a histogram =============================\n",
        "################################################################################\n",
        "\n",
        "# i: input layer, j: hidden layer, k: output layer\n",
        "\n",
        "# 1.1. Values selected by user -------------------------------------------------\n",
        "x_i_dict = {'x_1': -8, 'x_2': 0, 'x_3': 8}\n",
        "\n",
        "w_j_1_dict = {'w_i1_j1': -0.2, 'w_i2_j1': 0.5, 'w_i3_j1': -0.1}\n",
        "w_j_2_dict = {'w_i1_j2': -0.25, 'w_i2_j2': 0.1, 'w_i3_j2': 0.4}\n",
        "w_j_3_dict = {'w_i1_j3': 0.2, 'w_i2_j3': -0.3, 'w_i3_j3': -0.2}\n",
        "w_j_4_dict = {'w_i1_j4': 0.5, 'w_i2_j4': -0.8, 'w_i3_j4': 0.6}\n",
        "w_j_5_dict = {'w_i1_j5': 0.1, 'w_i2_j5': 0.4, 'w_i3_j5': 0.7}\n",
        "\n",
        "w_k_dict = {'w_j1_k1': -0.8, 'w_j2_k1': 0.1, 'w_j3_k1': -0.2,\n",
        "            'w_j4_k1': 0.4, 'w_j5_k1': 0.6}\n",
        "\n",
        "\n",
        "# 1.2. Randomly (Normally distributed) values ----------------------------------\n",
        "mu, sigma = 0, 0.05\n",
        "x_i_normal = np.random.normal(mu, sigma, 3)\n",
        "\n",
        "x_j_1_normal = np.random.normal(mu, sigma, 3)\n",
        "x_j_2_normal = np.random.normal(mu, sigma, 3)\n",
        "x_j_3_normal = np.random.normal(mu, sigma, 3)\n",
        "x_j_4_normal = np.random.normal(mu, sigma, 3)\n",
        "x_j_5_normal = np.random.normal(mu, sigma, 3)\n",
        "\n",
        "x_k_normal = np.random.normal(mu, sigma, 5)\n",
        "\n",
        "\n",
        "# Histogram of weights ---------------------------------------------------------\n",
        "n, bins, patches = plt.hist(w_k_dict.values(), 50, density=True, facecolor='g', alpha=0.75)\n",
        "\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of weights')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objectif de la tâche est d'encourager l'utilisateur à sélectionner les valeurs des entrées ainsi que les valeurs des poids, soit de manière aléatoire, soit de manière intentionnelle, et d'observer comment la sortie des neurones, ainsi que les pertinences, varient en fonction de ces changements.\n",
        "\n",
        "Les variables \"x_i_dict\", \"w_j_1_dict\" ... \"w_j_5_dict\", \"w_k_dict\" correspondent aux variables définies dans les équations mathématiques mentionnées ci-dessus. L'utilisateur peut également générer des poids suivant une distribution donnée ou complètement aléatoire. Dans cet exemple, nous les définissons selon une distribution gaussienne, mais cela peut être facilement remplacé par une autre méthode.\n"
      ],
      "metadata": {
        "id": "Uy_uTyWkxix9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les variables $( \\text{sum}_{j1}, \\text{sum}_{j2}, \\dots, \\text{sum}_{j5} )$ représentent les sommations pondérées des entrées $( x_i)$ et des poids $( w_{ij})$. Pour chaque neurone $x_j$​, la formule utilisée est la suivante :\n",
        "$$\n",
        "\\text{sum}_j = \\sum_{i} x_i \\cdot w_{ij}\n",
        "$$\n",
        "La sortie du réseau est calculée en additionnant les valeurs $(\\text{val}_{j1}, \\text{val}_{j2}, \\dots, \\text{val}_{j5})$ obtenues après l'application de la fonction ReLU :\n",
        "$$\n",
        "\\text{val}_{k1} = \\sum_{j} \\text{val}_{j}\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rH6r4ynLK9Vn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW1m7JNnSW-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dad8b95-d164-4dba-bd22-8c5fed704e22"
      },
      "source": [
        "################################################################################\n",
        "# [2.] Compute equations of feedforward pass ===================================\n",
        "# Apply those equations to compute the output of the network ===================\n",
        "################################################################################\n",
        "sum_j1 = x_i_dict['x_1'] * w_j_1_dict['w_i1_j1'] + \\\n",
        "         x_i_dict['x_2'] * w_j_1_dict['w_i2_j1'] + \\\n",
        "         x_i_dict['x_3'] * w_j_1_dict['w_i3_j1']\n",
        "\n",
        "sum_j2 = x_i_dict['x_1'] * w_j_2_dict['w_i1_j2'] + \\\n",
        "         x_i_dict['x_2'] * w_j_2_dict['w_i2_j2'] + \\\n",
        "         x_i_dict['x_3'] * w_j_2_dict['w_i3_j2']\n",
        "\n",
        "sum_j3 = x_i_dict['x_1'] * w_j_3_dict['w_i1_j3'] + \\\n",
        "         x_i_dict['x_2'] * w_j_3_dict['w_i2_j3'] + \\\n",
        "         x_i_dict['x_3'] * w_j_3_dict['w_i3_j3']\n",
        "\n",
        "sum_j4 = x_i_dict['x_1'] * w_j_4_dict['w_i1_j4'] + \\\n",
        "         x_i_dict['x_2'] * w_j_4_dict['w_i2_j4'] + \\\n",
        "         x_i_dict['x_3'] * w_j_4_dict['w_i3_j4']\n",
        "\n",
        "sum_j5 = x_i_dict['x_1'] * w_j_5_dict['w_i1_j5'] + \\\n",
        "         x_i_dict['x_2'] * w_j_5_dict['w_i2_j5'] + \\\n",
        "         x_i_dict['x_3'] * w_j_5_dict['w_i3_j5']\n",
        "\n",
        "# Apply ReLU -------------------------------------------------------------------\n",
        "val_j1 = max(0, sum_j1)\n",
        "val_j2 = max(0, sum_j2)\n",
        "val_j3 = max(0, sum_j3)\n",
        "val_j4 = max(0, sum_j4)\n",
        "val_j5 = max(0, sum_j5)\n",
        "\n",
        "# Compute the output of the NN -------------------------------------------------\n",
        "val_k1 = val_j1 + val_j2 + val_j3 + val_j4 + val_j5\n",
        "print(f\"Output value of the network: {val_k1}\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output value of the network: 11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SABHHAdEkEsw",
        "outputId": "8b351400-64ed-4082-fdf7-5687c2feca8b"
      },
      "source": [
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "# [3.] Compute the relevances of each neuron in all layers =====================\n",
        "# The relevances computations follow the mathematical formulas defined above. ==\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "# [3.1] Compute relevance of output layer (k) ==================================\n",
        "################################################################################\n",
        "R_k = val_k1\n",
        "\n",
        "print(f\"Relevances of neurons of k layer: {R_k}\")\n",
        "\n",
        "################################################################################\n",
        "# [3.2] Compute relevance of every one of the 5 neurons of the layer (j) =======\n",
        "################################################################################\n",
        "R_j1 = val_j1\n",
        "R_j2 = val_j2\n",
        "R_j3 = val_j3\n",
        "R_j4 = val_j4\n",
        "R_j5 = val_j5\n",
        "\n",
        "print(f\"Relevances of neurons of j layer: {R_j1}, {R_j2}, {R_j3}, {R_j4}, {R_j5}\")\n",
        "\n",
        "################################################################################\n",
        "# [3.3] Compute relevance of every one of the 3 neurons of the layer (i) =======\n",
        "################################################################################\n",
        "sum_j1_power = w_j_1_dict['w_i1_j1'] ** 2 + \\\n",
        "               w_j_1_dict['w_i2_j1'] ** 2 + \\\n",
        "               w_j_1_dict['w_i3_j1'] ** 2\n",
        "\n",
        "sum_j2_power = w_j_2_dict['w_i1_j2'] ** 2 + \\\n",
        "               w_j_2_dict['w_i2_j2'] ** 2 + \\\n",
        "               w_j_2_dict['w_i3_j2'] ** 2\n",
        "\n",
        "sum_j3_power = w_j_3_dict['w_i1_j3'] ** 2 + \\\n",
        "               w_j_3_dict['w_i2_j3'] ** 2 + \\\n",
        "               w_j_3_dict['w_i3_j3'] ** 2\n",
        "\n",
        "sum_j4_power = w_j_4_dict['w_i1_j4'] ** 2 + \\\n",
        "               w_j_4_dict['w_i2_j4'] ** 2 + \\\n",
        "               w_j_4_dict['w_i3_j4'] ** 2\n",
        "\n",
        "sum_j5_power = w_j_5_dict['w_i1_j5'] ** 2 + \\\n",
        "               w_j_5_dict['w_i2_j5'] ** 2 + \\\n",
        "               w_j_5_dict['w_i3_j5'] ** 2\n",
        "\n",
        "R_i1 = ((w_j_1_dict['w_i1_j1'] ** 2) / sum_j1_power) * R_j1 + \\\n",
        "       ((w_j_2_dict['w_i1_j2'] ** 2) / sum_j2_power) * R_j2 + \\\n",
        "       ((w_j_3_dict['w_i1_j3'] ** 2) / sum_j3_power) * R_j3 + \\\n",
        "       ((w_j_4_dict['w_i1_j4'] ** 2) / sum_j4_power) * R_j4 + \\\n",
        "       ((w_j_5_dict['w_i1_j5'] ** 2) / sum_j5_power) * R_j5\n",
        "\n",
        "R_i2 = ((w_j_1_dict['w_i2_j1'] ** 2) / sum_j1_power) * R_j1 + \\\n",
        "       ((w_j_2_dict['w_i2_j2'] ** 2) / sum_j2_power) * R_j2 + \\\n",
        "       ((w_j_3_dict['w_i2_j3'] ** 2) / sum_j3_power) * R_j3 + \\\n",
        "       ((w_j_4_dict['w_i2_j4'] ** 2) / sum_j4_power) * R_j4 + \\\n",
        "       ((w_j_5_dict['w_i2_j5'] ** 2) / sum_j5_power) * R_j5\n",
        "\n",
        "R_i3 = ((w_j_1_dict['w_i3_j1'] ** 2) / sum_j1_power) * R_j1 + \\\n",
        "       ((w_j_2_dict['w_i3_j2'] ** 2) / sum_j2_power) * R_j2 + \\\n",
        "       ((w_j_3_dict['w_i3_j3'] ** 2) / sum_j3_power) * R_j3 + \\\n",
        "       ((w_j_4_dict['w_i3_j4'] ** 2) / sum_j4_power) * R_j4 + \\\n",
        "       ((w_j_5_dict['w_i3_j5'] ** 2) / sum_j5_power) * R_j5\n",
        "\n",
        "\n",
        "print(f\"Relevances of neurons of i layer: {R_i1}, {R_i2}, {R_i3}\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevances of neurons of k layer: 3.8\n",
            "Relevances of neurons of j layer: 2.4, 0, 1.4000000000000001, 0, 0\n",
            "Relevances of neurons of i layer: 0.6494117647058824, 2.741176470588235, 0.4094117647058824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "tmV8fYl2kKlC",
        "outputId": "fbcc92b0-4793-4dff-8ab8-a1779b13a29e"
      },
      "source": [
        "################################################################################\n",
        "# Positivity and conservativity properties =====================================\n",
        "# For every input x and every neuron p the relevance is positive ===============\n",
        "# The sum of relevances of all neurons in layer (i) ============================\n",
        "# equals the sum of relevances of all neurons in layer (j) =====================\n",
        "################################################################################\n",
        "\n",
        "Math(r'\\forall \\mathbf{x}, p: R_p(\\mathbf{x}) \\geq 0 \\\\ \\sum_i R_i = \\sum_j R_j ')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle \\forall \\mathbf{x}, p: R_p(\\mathbf{x}) \\geq 0 \\\\ \\sum_i R_i = \\sum_j R_j $"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZhhnAyukppR",
        "outputId": "7896ca14-bb17-46d2-8e38-b42e7aab93bf"
      },
      "source": [
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "# [4.] Check that the computations of the relevance obay =======================\n",
        "# the positivity and conservativity properties =================================\n",
        "# (see cell above), with the help of assertions and unit tests =================\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# [4.1] Check positivity =======================================================\n",
        "################################################################################\n",
        "\n",
        "assert R_k >= 0, \"Relevance of every neuron of every layer must be positive\"\n",
        "\n",
        "assert R_j1 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "assert R_j2 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "assert R_j3 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "assert R_j4 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "assert R_j5 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "\n",
        "assert R_i1 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "assert R_i2 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "assert R_i3 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# [4.2] Check conservativity ===================================================\n",
        "################################################################################\n",
        "sum_Rj = R_j1 + R_j2 + R_j3 + R_j4 + R_j5\n",
        "print(f\" Conservativity j --to--> k: sum_Rj: {sum_Rj}, R_k: {R_k}\")\n",
        "\n",
        "\n",
        "sum_Ri = R_i1 + R_i2 + R_i3\n",
        "print(f\" Conservativity i --to--> j: sum_Ri: {sum_Ri}, sum_Rj: {sum_Rj}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Conservativity j --to--> k: sum_Rj: 3.8, R_k: 3.8\n",
            " Conservativity i --to--> j: sum_Ri: 3.8, sum_Rj: 3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DQ_Hh9Nkuen",
        "outputId": "f806716e-9626-4a27-a03f-281a72ba8e7c"
      },
      "source": [
        "import unittest\n",
        "\n",
        "class TestLRPProperties(unittest.TestCase):\n",
        "\n",
        "    def test_relevance_positivity(self):\n",
        "\n",
        "        assert R_k >= 0, \"Relevance of every neuron of every layer must be positive\"\n",
        "\n",
        "        assert R_j1 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "        assert R_j2 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "        assert R_j3 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "        assert R_j4 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "        assert R_j5 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "\n",
        "        assert R_i1 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "        assert R_i2 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "        assert R_i3 >=0, \"Relevance of every neuron of every layer must be positive\"\n",
        "\n",
        "\n",
        "    def test_relevance_conservativity(self):\n",
        "        self.assertEqual(R_k, R_j1 + R_j2 + R_j3 + R_j4 + R_j5)\n",
        "        self.assertEqual(R_j1 + R_j2 + R_j3 + R_j4 + R_j5, R_i1 + R_i2 + R_i3)\n",
        "\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_relevance_conservativity (__main__.TestLRPProperties.test_relevance_conservativity) ... ok\n",
            "test_relevance_positivity (__main__.TestLRPProperties.test_relevance_positivity) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.009s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7988b1318b10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}