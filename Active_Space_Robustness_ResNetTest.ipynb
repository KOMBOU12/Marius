{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOMBOU12/Marius/blob/main/Active_Space_Robustness_ResNetTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4lU8e1BwW4g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "from google.colab import drive\n",
        "import time\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzfdfs5pw5UP",
        "outputId": "65bf8e76-3b31-4dd5-c3f3-8b6bc0140e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive') ### connexion au drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H2QfLICw9ox",
        "outputId": "f70c3747-4ad9-4a01-deed-c3bc588252cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "file_name = \"/content/gdrive/MyDrive/Entrainement_05.zip\" ### il faut créer un fichier data_images dans le drive et y déposer le fichier zip Entrainement.zip\n",
        "with ZipFile(file_name,'r') as zip:                                ### cette partie du code dézip le fichier et le rend accessible dans le colab\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8sLGXq6w-aJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  ### définition de device si GPU disponibles et fonction pour tranformer les images\n",
        "\n",
        "mean  = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train' : transforms.Compose([\n",
        "       transforms.RandomResizedCrop(224),\n",
        "       transforms.RandomHorizontalFlip(),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize(mean,std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "       transforms.Resize(256),\n",
        "       transforms.CenterCrop(224),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize(mean,std)\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl1FSJ1SxGZI",
        "outputId": "9c2d31cb-d0ca-4dab-915c-e54bdfc8f472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BuggyCart', 'Camels', 'Dogs', 'Farms', 'Fruits', 'GoldenFish', 'Scorpions']\n"
          ]
        }
      ],
      "source": [
        "### Partie du code qui définit les fonctions d'entrainement et de test\n",
        "\n",
        "data_dir = \"/content/Entrainement_05\"\n",
        "sets = ['train', 'val']\n",
        "\n",
        "num_clas = 7\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir,x),data_transforms[x]) for x in sets}\n",
        "dataloaders = {x:torch.utils.data.DataLoader(image_datasets[x], batch_size = 64, shuffle=True, num_workers = 0) for x in sets}\n",
        "\n",
        "#dataloaders = {x:torch.utils.data.DataLoader(data_augmented[x], batch_size = 64, shuffle=True, num_workers = 0) for x in sets}\n",
        "\n",
        "\n",
        "datasets_size = {x: len(image_datasets[x]) for x in sets}\n",
        "#datasets_size = {x: len(data_augmented[x]) for x in sets}\n",
        "classe_names = image_datasets['train'].classes\n",
        "\n",
        "print(classe_names)\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs = 20):\n",
        "  since = time.time()\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f'Epoque {epoch}/{num_epochs -1}')\n",
        "    print('-'*20)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          if phase == 'train':\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "\n",
        "      epoch_loss = running_loss / datasets_size[phase]\n",
        "      epoch_acc  = running_corrects.double() / datasets_size[phase]\n",
        "\n",
        "      print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print(f'Entraînement complété en {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
        "  print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def test_model(model,criterion):\n",
        "  best_acc = 0.0\n",
        "  num_epochs = 1\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f'Epoque {epoch}/{num_epochs -1}')\n",
        "    print('-'*20)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      epoch_loss = running_loss / datasets_size[phase]\n",
        "      epoch_acc  = running_corrects.double() / datasets_size[phase]\n",
        "\n",
        "      print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    print()\n",
        "\n",
        "\n",
        "  print(f'Best val Acc: {best_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS-X7Oq0gXHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47c688d-7d30-4605-ded6-c2a1bb19e255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1630\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for img, label in dataloaders['train']:\n",
        "  for j in range(len(label)):\n",
        "   data.append((torch.reshape(img[j],(3,224,224)).to(device),label[j].item()))\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = []\n",
        "for img, label in dataloaders['val']:\n",
        "  for j in range(len(label)):\n",
        "   testdata.append((torch.reshape(img[j],(3,224,224)).to(device),label[j].item()))\n",
        "print(len(testdata))"
      ],
      "metadata": {
        "id": "etvBbedUhjOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe72f8f-7397-4dca-ed32-d8d11cccb081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "les_PDR = []\n",
        "for a,b,c in les_points_de_rupture_ResNet50:\n",
        "  les_PDR.append((torch.reshape(a[0],(3,224,224)).to(device),a[1]))\n",
        "for elem in data:\n",
        "  les_PDR.append(elem)"
      ],
      "metadata": {
        "id": "7IX054a_yyul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f078c811-7d02-44be-a294-a2ab5b3a7ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'les_points_de_rupture_ResNet50' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-15ec013d51d1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mles_PDR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mles_points_de_rupture_ResNet50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mles_PDR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mles_PDR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'les_points_de_rupture_ResNet50' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmented = {}\n",
        "data_augmented['train'] = les_PDR\n",
        "data_augmented['val'] = testdata\n"
      ],
      "metadata": {
        "id": "vtI6rRpQycjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hst7jIrxUGc"
      },
      "source": [
        "Modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KLmpmhWxPI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed78ea23-41e1-4c84-fbb3-2ce4ab823868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 81.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained = True)\n",
        "num_ftrs = model.fc.in_features\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, 7)\n",
        "model.to(device)\n",
        "model50 = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfB7TGJWxdFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7197529-cf30-4abd-c8e0-1a61652c8892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:02<00:00, 79.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet101(pretrained = True)\n",
        "num_ftrs = model.fc.in_features\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, 7)\n",
        "model.to(device)\n",
        "model101 = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrZ3VjqcxsiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0223c5af-b4ed-47f2-998c-f61a7df7ae91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:02<00:00, 86.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet152(pretrained = True)\n",
        "num_ftrs = model.fc.in_features\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, 7)\n",
        "model.to(device)\n",
        "model152 = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzr0j6SLxBqD"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()                                                 ### fonction loss, optimizer et le scheduler pour adapter le learning_rat\n",
        "\n",
        "optimizer50  = optim.SGD(model.parameters(), lr = 0.1)\n",
        "#optimizer101 = optim.SGD(model101.parameters(), lr = 0.01)\n",
        "#optimizer152 = optim.SGD(model152.parameters(), lr = 0.01)\n",
        "\n",
        "step_lr_scheduler50  = lr_scheduler.StepLR(optimizer50, step_size = 8, gamma = 0.5)\n",
        "#step_lr_scheduler101 = lr_scheduler.StepLR(optimizer101, step_size = 4, gamma = 0.5)\n",
        "#step_lr_scheduler152 = lr_scheduler.StepLR(optimizer152, step_size = 4, gamma = 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKQ2CtZOynCZ"
      },
      "source": [
        "Entraînement"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet18"
      ],
      "metadata": {
        "id": "6Htx6O1KAtSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, 7)\n",
        "model.to(device)\n",
        "\n",
        "model_save_name = 'ResNet18FinTune7.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "#model.load_state_dict(torch.load(path))\n",
        "print(\"done\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "Evk4B5WDAvCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e578ddc3-1d8d-4569-fb95-697a42348130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device  = 'cpu'"
      ],
      "metadata": {
        "id": "mMi34adhY-WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fct = model152.to(device)\n",
        "test_model(fct,criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ14G6mUUXOm",
        "outputId": "0691331f-aedb-41a5-8d75-ce0dee95c2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoque 0/0\n",
            "--------------------\n",
            "train Loss: 2.0041 Acc: 0.1755\n",
            "val Loss: 1.9987 Acc: 0.1565\n",
            "\n",
            "Best val Acc: 0.1565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8ah-ubZzq2g"
      },
      "source": [
        "ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwLbzo1DyRDD"
      },
      "outputs": [],
      "source": [
        "model50 = train_model(model50, criterion, optimizer50, step_lr_scheduler50, num_epochs = 16)   ### Entraînement\n",
        "\n",
        "model_save_name = 'ResNet50FinTune7.pt'                                                        ### Sauvgarde du modèle sur le drive\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model50.state_dict(), path)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSUEGAmyzGRI"
      },
      "outputs": [],
      "source": [
        "model50 = models.resnet50()                                                                    ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model50.fc.in_features\n",
        "\n",
        "model50.fc = nn.Linear(num_ftrs, 7)\n",
        "model50.to(device)\n",
        "\n",
        "model_save_name = 'ResNet50FinTune7.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model50.load_state_dict(torch.load(path))\n",
        "print(\"done\")\n",
        "model50.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50_05"
      ],
      "metadata": {
        "id": "S6WkyJ3CtJiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model50_05 = models.resnet50(pretrained=True)                                                                    ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model50_05.fc.in_features\n",
        "\n",
        "model50_05.fc = nn.Linear(num_ftrs, 7)\n",
        "model50_05.to(device)"
      ],
      "metadata": {
        "id": "nV9739T6tMVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model50_05 = train_model(model50_05, criterion, optimizer50, step_lr_scheduler50, num_epochs = 16)   ### Entraînement\n",
        "\n",
        "model_save_name = 'ResNet50_05FinTune7.pt'                                                        ### Sauvgarde du modèle sur le drive\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model50_05.state_dict(), path)\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "VKHnGgsptcpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model50_05 = models.resnet50()                                                                    ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model50_05.fc.in_features\n",
        "\n",
        "model50_05.fc = nn.Linear(num_ftrs, 7)\n",
        "model50_05.to(device)\n",
        "\n",
        "model_save_name = 'ResNet50_05FinTune7.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model50_05.load_state_dict(torch.load(path))\n",
        "print(\"done\")\n",
        "model50_05.to(device)"
      ],
      "metadata": {
        "id": "kQbl1Qk1tv_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50 post points de ruptures"
      ],
      "metadata": {
        "id": "cKZOLjv9h3BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model50PDR = models.resnet50(pretrained = True)                                                                    ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model50PDR.fc.in_features\n",
        "\n",
        "model50PDR.fc = nn.Linear(num_ftrs, 7)\n",
        "model50PDR.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "FfAsAgyuh76C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model50PDR = train_model(model50PDR, criterion, optimizer50, step_lr_scheduler50, num_epochs = 16)   ### Entraînement\n",
        "\n",
        "model_save_name = 'ResNet50PDRFinTune7.pt'                                                        ### Sauvgarde du modèle sur le drive\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model50PDR.state_dict(), path)\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "fIXp1Iq31gjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model50PDR = models.resnet50()                                                                    ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model50PDR.fc.in_features\n",
        "\n",
        "model50PDR.fc = nn.Linear(num_ftrs, 7)\n",
        "model50PDR.to(device)\n",
        "\n",
        "model_save_name = 'ResNet50PDRFinTune7.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model50PDR.load_state_dict(torch.load(path))\n",
        "print(\"done\")\n",
        "model50PDR.to(device)"
      ],
      "metadata": {
        "id": "mDSyhZxZMMsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QGFF9VfzuMv"
      },
      "source": [
        "ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8cPESkItYeU"
      },
      "outputs": [],
      "source": [
        "model152 = train_model(model, criterion, optimizer152, step_lr_scheduler152, num_epochs = 16)  ### Entraînement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVmEPClmySBn"
      },
      "outputs": [],
      "source": [
        "model101 = train_model(model101, criterion, optimizer101, step_lr_scheduler101, num_epochs = 16)  ### Entraînement\n",
        "\n",
        "model_save_name = 'ResNet101FinTune7.pt'                                                       ### Sauvgarde du modèle sur le drive\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model101.state_dict(), path)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSv9GylVmtxr"
      },
      "outputs": [],
      "source": [
        "### cellule permetant de calculer les points de rupture\n",
        "\n",
        "e = 0.001\n",
        "fct = model152\n",
        "les_points_de_rupture_ResNet101 = PointDeRupture(fct,data,e,p=2,version = -1)\n",
        "\n",
        "ASMetric = []\n",
        "EucDist = []\n",
        "\n",
        "for j in range(7):\n",
        "  ASMetric.append([])\n",
        "  EucDist.append([])\n",
        "\n",
        "for a,b,c in les_points_de_rupture_ResNet101:\n",
        "  ASMetric[a[1]].append(c.item())\n",
        "  EucDist[a[1]].append(b.item())\n",
        "\n",
        "Gene_Graphe_colinéarités(ASMetric,\"Stability Metric study of ResNet152\")\n",
        "Gene_Graphe_colinéarités(EucDist,\"Euclidian distance between tipping point and the original point of ResNet152\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "uU49ez5ZLN_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNNjBVg3anQw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "test_model(model50_05,criterion)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "model50 = model50.to(device)\n",
        "test_model(model50,criterion)"
      ],
      "metadata": {
        "id": "nWYvB3vgEY-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "model50 = model50.to(device)\n",
        "test_model(model50,criterion)"
      ],
      "metadata": {
        "id": "_mjeO5t4Hhv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "model50PDR = model50PDR.to(device)\n",
        "test_model(model50PDR,criterion)"
      ],
      "metadata": {
        "id": "65oQp6uqHjkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3-mtAd1zIGR"
      },
      "outputs": [],
      "source": [
        "model101 = models.resnet101(pretrained = True)                                                                  ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model101.fc.in_features\n",
        "\n",
        "model101.fc = nn.Linear(num_ftrs, 7)\n",
        "model101.to(device)\n",
        "\n",
        "model_save_name = 'ResNet101FinTune7.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model101.load_state_dict(torch.load(path))\n",
        "print(\"done\")\n",
        "model101.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQGnSxLLfeks"
      },
      "outputs": [],
      "source": [
        "test_model(model101,criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlUyq3a6fcM3"
      },
      "source": [
        "ResNet152"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTaJHVIFzwXJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FmMOjEAySZ6"
      },
      "outputs": [],
      "source": [
        "model152 = train_model(model152, criterion, optimizer152, step_lr_scheduler152, num_epochs = 16)  ### Entraînement\n",
        "\n",
        "model_save_name = 'ResNet152FinTune7.pt'                                                          ### Sauvgarde du modèle sur le drive\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "torch.save(model152.state_dict(), path)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q_-CU59y-kx"
      },
      "outputs": [],
      "source": [
        "model152 = models.resnet152(pretrained = True)                                                                    ### Recupèration du modèle suavgardé\n",
        "\n",
        "num_ftrs = model152.fc.in_features\n",
        "\n",
        "model152.fc = nn.Linear(num_ftrs, 7)\n",
        "model152.to(device)\n",
        "\n",
        "model_save_name = 'ResNet152FinTune7.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model152.load_state_dict(torch.load(path))\n",
        "print(\"done\")\n",
        "model152.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOUyX-_l0BJm"
      },
      "source": [
        "stabilité"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOwb27DIy-r5"
      },
      "outputs": [],
      "source": [
        "### Cette partie du code n'est pas sensée être modifiée Il faut juste executer cette cellule pour que les fonctions soient définies\n",
        "\n",
        "def Trajctoires(fct,elem,e, p, version):\n",
        "  for param in fct.parameters():\n",
        "    param.requires_grad = False\n",
        "  print(\"Start\")\n",
        "  l = []\n",
        "  u,q = elem\n",
        "  u = torch.reshape(u,(1,3, 224, 224)).to(device)\n",
        "  fct.eval()\n",
        "  A = True\n",
        "  with torch.no_grad():\n",
        "      output = fct(u)\n",
        "  l.append(output.cpu().numpy())\n",
        "  while A:\n",
        "    with torch.no_grad():\n",
        "      output = fct(u)\n",
        "    x = torch.autograd.functional.jacobian(fct,u)[0]\n",
        "    x = UpDate( x, output, q, p, version)\n",
        "    x = e*x\n",
        "    x = torch.reshape(torch.from_numpy(x),(1,3,224,224))\n",
        "    x = x.to(device)\n",
        "    v = (u + x).float()\n",
        "    with torch.no_grad():\n",
        "      output_1 = fct(v)\n",
        "      y_pred = output_1.argmax(1)\n",
        "    u = v\n",
        "    l.append(output_1.cpu().numpy())\n",
        "    if y_pred.item()!= q:\n",
        "      A = False\n",
        "  return np.array(l)\n",
        "\n",
        "\n",
        "def UnPoinDeRupture(fct,elem,e, p, version):\n",
        "  for param in fct.parameters():\n",
        "    param.requires_grad = False\n",
        "  print(\"Start\")\n",
        "\n",
        "  u,q = elem\n",
        "  u = torch.reshape(u,(1,3, 224, 224)).to(device)\n",
        "\n",
        "  fct.eval()\n",
        "  A = True\n",
        "  val = 0\n",
        "  while A:\n",
        "    with torch.no_grad():\n",
        "      output = fct(u)\n",
        "    x = torch.autograd.functional.jacobian(fct,u)[0]\n",
        "    x = UpDate( x, output, q, p, version)\n",
        "    x = e*x\n",
        "    x = torch.reshape(torch.from_numpy(x),(1,3,224,224))\n",
        "    x = x.to(device)\n",
        "    v = (u + x).float()\n",
        "    val = metric1(v,val,e)\n",
        "    with torch.no_grad():\n",
        "      output_1 = fct(v)\n",
        "      y_pred = output_1.argmax(1)\n",
        "    u = v\n",
        "    if y_pred.item()!= q:\n",
        "      A = False\n",
        "\n",
        "    #normm = torch.norm(input=v-data[1][0], p='fro', dim=None, keepdim=False, out=None, dtype=None)\n",
        "\n",
        "  return ((v,q,elem[0]),norm(v-elem[0]),val)\n",
        "\n",
        "def PointDeRupture(fct,data,e,p=2, version = -1):\n",
        "  \"\"\" prend en paramètre\n",
        "  -> une classifieur fct\n",
        "  -> des données data\n",
        "  -> un pas de déplacement e\n",
        "  -> un flotant p ou 'inf' pour infinity\n",
        "  -> la vérsion de la l'algorithme -1 prend en compte toutes les classes 1 prend en compte le premier adversaire, 2 prend en compte les deux plus forts...\n",
        "  \"\"\"\n",
        "  since = time.time()\n",
        "  res = []\n",
        "  taille = len(data)\n",
        "  j = 0\n",
        "  for param in fct.parameters():\n",
        "    param.requires_grad = False\n",
        "  print(\"Start\")\n",
        "  for elem in data:\n",
        "    u,q = elem\n",
        "    u = torch.reshape(u,(1,3, 224, 224)).to(device)\n",
        "    fct.eval()\n",
        "    A = True\n",
        "    val = 0\n",
        "    while A:\n",
        "      with torch.no_grad():\n",
        "        output = fct(u)\n",
        "      x = torch.autograd.functional.jacobian(fct,u)[0]\n",
        "      x = UpDate( x, output, q, p, version)\n",
        "      x = e*x\n",
        "      x = torch.reshape(torch.from_numpy(x),(1,3,224,224))\n",
        "      x = x.to(device)\n",
        "      v = (u + x).float()\n",
        "      val = metric1(v,val,e)\n",
        "      with torch.no_grad():\n",
        "        output_1 = fct(v)\n",
        "        y_pred = output_1.argmax(1)\n",
        "      u = v\n",
        "      if y_pred.item()!= q:\n",
        "        A = False\n",
        "\n",
        "      #normm = torch.norm(input=v-data[1][0], p='fro', dim=None, keepdim=False, out=None, dtype=None)\n",
        "    now = time.time()\n",
        "    uptonow = round((now - since)/60)\n",
        "    j+= 1\n",
        "    ratio = round(j/taille,3)\n",
        "    res.append(((v,q,elem[0]),Norm(v-elem[0],p),val))         ### ce qui est enregistré est (a,b,c) avec a contenant le point de rupture la classe à la quelle il est rataché ainsi que l'image de départ\n",
        "    print(\"Pourcentage de travail avancé :\" + str(ratio*100))       ### b est la norme p entre le point de départ et le point de rupture\n",
        "    print(\"--\"*15)                                                  ### c est la métrique de stabilité\n",
        "    print(\"Temps de travail :\" + str(uptonow))\n",
        "    print(\"--\"*15)\n",
        "  print(\"Done\")\n",
        "  return res\n",
        "\n",
        "\n",
        "def Version(output,q, version):\n",
        "  \"\"\"output est la sortie du nn, q est la classe qu'on étudie et version est un entier compris entre 1 et 6 ou égale à -1\n",
        "  version correspond au nombre de classes prises en compte pour le calcule du chemin actif (-1) c'est toutes les classes\n",
        "  et les autres valeurs de version c'est assez clair\n",
        "  \"\"\"\n",
        "  if version == -1:\n",
        "    output = output.cpu().numpy()\n",
        "    output = SofTMax(output[0])\n",
        "    output[q] *= -1\n",
        "    return output\n",
        "\n",
        "  elif version == 8:\n",
        "    v = output.clone().cpu()\n",
        "    output = output.cpu().numpy()\n",
        "    v[0][q] = -100000\n",
        "    mm, preds = torch.max(v,1)\n",
        "    res = np.zeros(output[0].shape)\n",
        "    res[q] = -0.5\n",
        "    res[preds.item()] = 0.5\n",
        "    return res\n",
        "\n",
        "  elif version == 9:\n",
        "    o = output.cpu().numpy()\n",
        "    o = o[0]\n",
        "    mm, preds = torch.min(output,1)\n",
        "    if mm.item()<0:\n",
        "      o -= mm.item()\n",
        "    else:\n",
        "      o += mm.item()\n",
        "    o /= np.linalg.norm(o,1)\n",
        "    o[q] *= -1\n",
        "    return o\n",
        "\n",
        "  else:\n",
        "    l= np.zeros(output[0].shape)\n",
        "    l[q] = 1\n",
        "    v = output.clone().cpu()\n",
        "    v[0][q] = -100000\n",
        "    for j in range(version):\n",
        "      mm, preds = torch.max(v,1)\n",
        "      l[preds.item()] = 1\n",
        "      v[0][preds] = -100000\n",
        "    output = output.cpu().numpy()\n",
        "    output = output[0]*np.array(l)\n",
        "    res = 0\n",
        "    ll = []\n",
        "\n",
        "    for j in range(len(l)):\n",
        "      c = np.exp(output[j])\n",
        "      res += c\n",
        "      output[j] = l[j]*c\n",
        "    output[q] *= -1\n",
        "    return output/res\n",
        "\n",
        "\n",
        "def SofTMax(output):\n",
        "  res = []\n",
        "  sftm = 0\n",
        "  for j in range(output.shape[0]):\n",
        "    y = np.exp(output[j])\n",
        "    res.append(y)\n",
        "    sftm += y\n",
        "  res = np.array(res)/(sftm + 10**(-12))\n",
        "  return res\n",
        "\n",
        "\n",
        "def UpDate(x,output,q,p,version):\n",
        "  u = []\n",
        "  output = Version(output,q,version)\n",
        "  for j in range(len(x)):\n",
        "    u.append(ReNorm(torch.reshape(x[j],(-1,)),p).cpu().numpy())\n",
        "  u = np.array(u)\n",
        "  u = np.dot(np.transpose(u),np.transpose(output))\n",
        "  return u\n",
        "\n",
        "\n",
        "def UpDate2(x,output,q):\n",
        "  u = []\n",
        "  output = output.cpu().numpy()\n",
        "  output = SofTMax(output)\n",
        "  output[0][q] = -output[0][q]\n",
        "  for j in range(len(x)):\n",
        "    w = torch.reshape(x[j],(1,3*224*224))\n",
        "    mm, preds = torch.max(w,1)\n",
        "    mm = mm.item()\n",
        "    u.append((1/mm)*w.cpu().numpy())\n",
        "  u = np.array(u)\n",
        "  u = np.dot(np.transpose(u),np.transpose(output))\n",
        "  return u\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def visionEval(x,fct):\n",
        "  pred_probab = fct(x)\n",
        "  y_pred = pred_probab.argmax(1)\n",
        "  print(f\"Predicted class: {y_pred}\")\n",
        "  z = x.to('cpu')\n",
        "  out = torchvision.utils.make_grid(z)\n",
        "  imshow(out, title=None)\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def ReNorm_v1(u):\n",
        "  m = torch.nn.functional.normalize(u, p=2, dim=0, eps=1e-12, out=None)\n",
        "  return m\n",
        "\n",
        "\n",
        "def ReNorm(u,p):\n",
        "  m = Norm(u,p)\n",
        "  if m == 0:\n",
        "    m = 10**(-12)\n",
        "  return u/m\n",
        "\n",
        "def norm(u):\n",
        "    return torch.norm(u)\n",
        "\n",
        "\n",
        "def norm1(u):\n",
        "    return torch.norm(u,p=1)\n",
        "\n",
        "def norm_inf(u):\n",
        "    w = torch.reshape(u,(1,3*224*224))\n",
        "    mm, preds = torch.max(w,1)\n",
        "    mm = mm.item()\n",
        "    return mm\n",
        "\n",
        "\n",
        "def Norm(u,p=2):\n",
        "    if p == 'inf':\n",
        "      w = torch.reshape(u,(1,3*224*224))\n",
        "      mm, preds = torch.max(w,1)\n",
        "      mm = mm.item()\n",
        "      return mm\n",
        "    else:\n",
        "      return torch.norm(u,p=p)\n",
        "\n",
        "def metric1(v,val,e):\n",
        "    val = val + e*norm(v)\n",
        "    return val\n",
        "\n",
        "def metric2(v,val,e):\n",
        "    val = val - e*norm(v)\n",
        "    return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-12V5KpmOhmE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMBK6NlZOjKA"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  pred = model152(data[0][0].reshape((1,3,224,224)))\n",
        "print(pred)\n",
        "q = pred.cpu().numpy()\n",
        "print(q[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFS-kHuLO5xq"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(Version(pred,6, 9))\n",
        "print(np.sum(Version(pred,6, 9)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLHjI4_UPnr7"
      },
      "outputs": [],
      "source": [
        "print(SofTMax(pred.cpu().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1VZp9no0PL-"
      },
      "source": [
        "Calibrage du pas de déplacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjOuhh3a0THP"
      },
      "outputs": [],
      "source": [
        "### cette cellule trie l'ensemble des images selon les classes et tire aléatoirement n images par classe\n",
        "n = 1\n",
        "\n",
        "datasorted = [[],[],[],[],[],[],[]]\n",
        "for x,y in data:\n",
        "  datasorted[y].append((x,y))\n",
        "\n",
        "precision_test_data = []\n",
        "randsample = [[],[],[],[],[],[],[]]\n",
        "for i in range(len(randsample)):\n",
        "  randsample[i] = random.sample(range(len(datasorted[i])),n)\n",
        "\n",
        "for j in range(7):\n",
        "  for s in randsample[j]:\n",
        "    precision_test_data.append(datasorted[j][s])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3K0SepPBBqY"
      },
      "outputs": [],
      "source": [
        "### partie du code qui détermine le pas de déplacement dans l'algo des points de rupture\n",
        "fct  = model\n",
        "calibrage = []\n",
        "precision = [0.05,0.01,0.005,0.001,0.0005,0.0001]\n",
        "for e in precision:\n",
        "  test_data = PointDeRupture(fct,precision_test_data,e,p=2,version = -1)\n",
        "  res = 0\n",
        "  for a,b,c in test_data:\n",
        "    res+=c\n",
        "  calibrage.append((res/len(test_data)).item())\n",
        "\n",
        "### Affichage\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
        "taille = len(precision)\n",
        "x = np.linspace(1,taille,taille)\n",
        "axs.scatter(x,calibrage,linewidths = 8)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def colin(x,y):\n",
        "  x,y = x.cpu(), y.cpu()\n",
        "  x,y = x.reshape((-1,)), y.reshape((-1,))\n",
        "  x,y = x/torch.norm(x,p=2), y/torch.norm(y,p=2)\n",
        "  a = torch.matmul(x,y)\n",
        "  return a.item()\n",
        "\n",
        "\n",
        "def stat_test_versions(fct,data):\n",
        "  l = [[],[],[]]\n",
        "  for elem in data:\n",
        "    l[0].append(numpisation(UnPoinDeRupture(fct,elem,0.01, 2, -1)[0]))\n",
        "    l[1].append(numpisation(UnPoinDeRupture(fct,elem,0.01, 2, 8)[0]))\n",
        "    l[2].append(numpisation(UnPoinDeRupture(fct,elem,0.01, 2, 9)[0]))\n",
        "  return np.array(l)\n",
        "\n",
        "def numpisation(elem):\n",
        "  x,q,a = elem\n",
        "  l= [x.cpu().numpy(),a.cpu().numpy()]\n",
        "  return np.array(l)\n",
        "### test ###\n",
        "\n",
        "\n",
        "res = stat_test_versions(model,data)"
      ],
      "metadata": {
        "id": "-xGtpHVzD9FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for j in range(len(res[0])):\n",
        "  x,a = res[0][j]\n",
        "  y,b = res[1][j]\n",
        "  z,c = res[2][j]\n",
        "  x = torch.from_numpy(x-a)\n",
        "  y = torch.from_numpy(y-b)\n",
        "  z = torch.from_numpy(z-c)\n",
        "  l.append((colin(x,y),colin(z,y),colin(x,z)))\n",
        "l = np.array(l)/len(res[0])\n",
        "\n",
        "print(np.sum(l,axis=0))\n"
      ],
      "metadata": {
        "id": "P5l-7Ry_GgP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(l,axis=0)"
      ],
      "metadata": {
        "id": "p3aY78oGKvob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlbjbsmrBEHd"
      },
      "outputs": [],
      "source": [
        "### partie du code qui détermine le pas de déplacement dans l'algo des points de rupture\n",
        "fct  = model152\n",
        "calibrage = []\n",
        "precision = [0.05,0.01,0.005,0.001]#,0.0005,0.0001]\n",
        "for e in precision:\n",
        "  test_data = PointDeRupture(fct,precision_test_data,e,p=2,version = 1)\n",
        "  res = 0\n",
        "  for a,b,c in test_data:\n",
        "    res+=c\n",
        "  calibrage.append((res/len(test_data)).item())\n",
        "\n",
        "### Affichage\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
        "taille = len(precision)\n",
        "x = np.linspace(1,taille,taille)\n",
        "axs.scatter(x,calibrage,linewidths = 8)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device\n"
      ],
      "metadata": {
        "id": "zNdSE0XzMMfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5_wp_rVy-xG"
      },
      "outputs": [],
      "source": [
        "### permet de créer un ensemble d'images pour faire tourner l'algo des points de rupture\n",
        "#data = []\n",
        "#for img, label in dataloaders['train']:\n",
        "#  for j in range(len(label)):\n",
        "#    data.append((torch.reshape(img[j],(3,224,224)).to(device),label[j].item()))\n",
        "\n",
        "### cellule permetant de calculer les points de rupture\n",
        "\n",
        "e = 0.1\n",
        "fct = model50_05.to(device)\n",
        "\n",
        "#t = time.time()\n",
        "#les_points_de_rupture_ResNet50pdr = PointDeRupture(fct,data,e,p=2,version = 8)\n",
        "#s = time.time()\n",
        "\n",
        "tt = time.time()\n",
        "les_points_de_rupture_ResNet50 = PointDeRupture(fct,data,e,p=2,version = 8)\n",
        "ss = time.time()\n",
        "\n",
        "#nom = str(les_points_de_rupture_ResNet50)\n",
        "#path = '/content/gdrive/MyDrive/' + nom + '.pickle'\n",
        "\n",
        "#with open(path, 'wb') as f_lpr:\n",
        "#   pickle.dump(les_points_de_rupture_ResNet50, f_lpr)\n",
        "\n",
        "\n",
        "#ASMetric = []\n",
        "#EucDist = []\n",
        "\n",
        "#for j in range(7):\n",
        "#  ASMetric.append([])\n",
        "#  EucDist.append([])\n",
        "\n",
        "#for a,b,c in les_points_de_rupture_ResNet50pdr:\n",
        "#  ASMetric[a[1]].append(c.item())\n",
        "#  EucDist[a[1]].append(b.item())\n",
        "\n",
        "#Gene_Graphe_colinéarités(ASMetric,\"Stability metric study of ResNet50PDR\")\n",
        "\n",
        "#Gene_Graphe_colinéarités(EucDist,\"Euclidean distance between tipping point and the original point of ResNet50PDR\")\n",
        "\n",
        "ASMetric = []\n",
        "EucDist = []\n",
        "\n",
        "for j in range(7):\n",
        "  ASMetric.append([])\n",
        "  EucDist.append([])\n",
        "\n",
        "for a,b,c in les_points_de_rupture_ResNet50:\n",
        "  ASMetric[a[1]].append(c.item())\n",
        "  EucDist[a[1]].append(b.item())\n",
        "\n",
        "Gene_Graphe_colinéarités(ASMetric,\"Stability metric study of ResNet50_05\")\n",
        "\n",
        "Gene_Graphe_colinéarités(EucDist,\"Euclidean distance between tipping point and the original point of ResNet50_05\")\n",
        "#print('Le temps :' + str(s-t))\n",
        "print('Le temps :' + str(ss-tt))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gene_Graphe_colinéarités(ASMetric,\"Stability metric study of ResNet50_05\")\n",
        "\n",
        "Gene_Graphe_colinéarités(EucDist,\"Euclidean distance between tipping point and the original point of ResNet50_05\")\n",
        "#print('Le temps :' + str(s-t))"
      ],
      "metadata": {
        "id": "PgIjTPfIqq2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/MyDrive/data.pickle', 'wb') as f_w:\n",
        "    pickle.dump(les_points_de_rupture_ResNet50t_pdr, f_w)\n"
      ],
      "metadata": {
        "id": "GP2VGC4mGFj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/MyDrive/data.pickle', 'rb') as f_r:\n",
        "    les_points_de_rupture_ResNet50t_pdr = pickle.load(f_r)"
      ],
      "metadata": {
        "id": "36exLEMHFP1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYj6R84yLXpy"
      },
      "outputs": [],
      "source": [
        "Gene_Graphe_colinéarités(ASMetric_t,\"__\")\n",
        "\n",
        "Gene_Graphe_colinéarités(EucDist_t,\"___\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLBeeEyh1kp1"
      },
      "source": [
        "Graphiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cSCfrU52N2T"
      },
      "outputs": [],
      "source": [
        "def Gene_Graphe_colinéarités(las,nom_du_graphique):\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(19, 8))\n",
        "\n",
        "  # generate some random test data\n",
        "  all_data = las\n",
        "\n",
        "  # plot box plot\n",
        "  axs.boxplot(all_data)\n",
        "  axs.set_title(nom_du_graphique)\n",
        "\n",
        "\n",
        "  axs.yaxis.grid(True)\n",
        "\n",
        "  axs.set_xlabel(\"\")\n",
        "  axs.set_ylabel('Observed values')\n",
        "\n",
        "  # add x-tick labels\n",
        "\n",
        "\n",
        "  plt.setp(axs, xticks=[y + 1 for y in range(len(all_data))],\n",
        "          xticklabels = classe_names)\n",
        "\n",
        "  plt.savefig(nom_du_graphique+'.pdf')\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GffUg58m1m5e"
      },
      "outputs": [],
      "source": [
        "### Cette cellule recupère l'information fournie par l'algo des points de rupture\n",
        "\n",
        "ASMetric = []\n",
        "EucDist = []\n",
        "\n",
        "for j in range(7):\n",
        "  ASMetric.append([])\n",
        "  EucDist.append([])\n",
        "\n",
        "for a,b,c in les_points_de_rupture_ResNet50:\n",
        "  ASMetric[a[1]].append(c.item())\n",
        "  EucDist[a[1]].append(b.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOpqynAR1vxA"
      },
      "outputs": [],
      "source": [
        "ASM = [0,0,0,0,0,0,0]\n",
        "Euc = [0,0,0,0,0,0,0]\n",
        "\n",
        "for a,b,c in les_points_de_rupture_ResNet50:\n",
        "  ASM[a[1]] += c.item()\n",
        "  Euc[a[1]] += b.item()\n",
        "\n",
        "ASM = np.array(ASM)/len(les_points_de_rupture_ResNet50)\n",
        "Euc = np.array(Euc)/len(les_points_de_rupture_ResNet50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4JUqdNK25nL"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
        "taille = 7\n",
        "x = np.linspace(1,taille,taille)\n",
        "axs.scatter(x, ASM,linewidths = 8, label = 'ASM distance')\n",
        "axs.scatter(x, Euc,linewidths = 8, label = 'Euclidean distance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sevQR4FR2J1J"
      },
      "outputs": [],
      "source": [
        "Gene_Graphe_colinéarités(ASMetric,\"Stability Metric study of ResNet152\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8hMOFiX2c0G"
      },
      "outputs": [],
      "source": [
        "Gene_Graphe_colinéarités(EucDist,\"Euclidian distance between tipping point and the original point of ResNet152\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzJ5r8MMjQD0"
      },
      "source": [
        "D'autres graphes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9elF3-mpgPJf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjK0hMt3jnPg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Ryrmd__mn7"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    u = torch.clone(precision_test_data[0][0])\n",
        "    pred = model152(torch.reshape(u,(1,3, 224, 224)).to(device))\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBLZzlfGBRFP"
      },
      "outputs": [],
      "source": [
        "fct  = model152\n",
        "e = 0.01\n",
        "\n",
        "res7 = Trajctoires(fct,precision_test_data[0],e,2, -1)\n",
        "print('fait')\n",
        "res0 = Trajctoires(fct,precision_test_data[0],e,2, 0)\n",
        "print('fait')\n",
        "res1 = Trajctoires(fct,precision_test_data[0],e,2, 1)\n",
        "print('fait')\n",
        "res2 = Trajctoires(fct,precision_test_data[0],e,2, 2)\n",
        "print('fait')\n",
        "res3 = Trajctoires(fct,precision_test_data[0],e,2, 3)\n",
        "print('fait')\n",
        "res4 = Trajctoires(fct,precision_test_data[0],e,2, 4)\n",
        "print('fait')\n",
        "res8 = Trajctoires(fct,precision_test_data[0],e,2, 8)\n",
        "print('fait')\n",
        "res9 = Trajctoires(fct,precision_test_data[0],e,2, 9)\n",
        "print('fait')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywjem4VdCCZP"
      },
      "outputs": [],
      "source": [
        "figure, axs  = plt.subplots(2,4, figsize = (20,10))\n",
        "\n",
        "axs[0,0].plot(res7[:,0,:])\n",
        "\n",
        "axs[0,1].plot(res0[:,0,:])\n",
        "\n",
        "axs[0,2].plot(res1[:,0,:])\n",
        "\n",
        "axs[0,3].plot(res2[:,0,:])\n",
        "\n",
        "axs[1,0].plot(res3[:,0,:])\n",
        "\n",
        "axs[1,1].plot(res4[:,0,:])\n",
        "\n",
        "axs[1,2].plot(res8[:,0,:])\n",
        "\n",
        "axs[1,3].plot(res9[:,0,:])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KkwqKzxfpJV"
      },
      "outputs": [],
      "source": [
        "res8 = Trajctoires(fct,precision_test_data[0],e,2, 8)\n",
        "print('fait')\n",
        "figure, axs  = plt.subplots(1,1, figsize = (5,3))\n",
        "\n",
        "axs.plot(res[:,0,:])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY1qk-4ziEa3"
      },
      "outputs": [],
      "source": [
        "#res9 = Trajctoires(fct,precision_test_data[0],e,2, 8)\n",
        "print('fait')\n",
        "figure, axs  = plt.subplots(1,1, figsize = (5,3))\n",
        "\n",
        "axs.plot(res9[:,0,:])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlACjiBPxrCA"
      },
      "outputs": [],
      "source": [
        "print(res7[-1])\n",
        "print(\"##\"*25)\n",
        "print(res1[-1])\n",
        "print(\"##\"*25)\n",
        "print(res2[-1])\n",
        "print(\"##\"*25)\n",
        "print(res3[-1])\n",
        "print(\"##\"*25)\n",
        "print(res4[-1])\n",
        "print(\"##\"*25)\n",
        "print(res5[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jChjEhX4kAj-"
      },
      "outputs": [],
      "source": [
        "classif2= [[],[],[],[],[],[],[]]\n",
        "for a,b,c in test_data2:\n",
        "  with torch.no_grad():\n",
        "    u = torch.clone(a[-1])\n",
        "    v = torch.clone(a[0])\n",
        "    pred = model152(torch.reshape(u,(1,3, 224, 224)).to(device))\n",
        "    fred = model152(torch.reshape(v,(1,3, 224, 224)).to(device))\n",
        "    res = torch.argmax(pred).item()\n",
        "    ser = torch.argmax(fred).item()\n",
        "    classif2[res].append((res,ser))\n",
        "    print(\"ASM\")\n",
        "    print(c)\n",
        "    print(\"Euc\")\n",
        "    print(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### cette cellule trie l'ensemble des images selon les classes et tire aléatoirement n images par classe\n",
        "n = 1\n",
        "\n",
        "datasorted = [[],[],[],[],[],[],[]]\n",
        "for x,y in data:\n",
        "  datasorted[y].append((x,y))\n",
        "\n",
        "precision_test_data = []\n",
        "randsample = [[],[],[],[],[],[],[]]\n",
        "for i in range(len(randsample)):\n",
        "  randsample[i] = random.sample(range(len(datasorted[i])),n)\n",
        "\n",
        "for j in range(7):\n",
        "  for s in randsample[j]:\n",
        "    precision_test_data.append(datasorted[j][s])"
      ],
      "metadata": {
        "id": "HbwzO3c5pGz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Aug(x,a):\n",
        "  x = x.cpu().reshape((3,224,224))\n",
        "  x = np.abs(x.numpy())\n",
        "  x = torchvision.utils.make_grid(torch.from_numpy(np.exp(a*x) -1))\n",
        "  x = x.numpy().transpose((1, 2, 0))\n",
        "  x = std * x + mean\n",
        "  x = np.clip(x, 0, 1)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "fct  = model152\n",
        "e = 0.01\n",
        "grid_data2 = [[],[],[],[],[],[],[]]\n",
        "\n",
        "test_data2 = []\n",
        "for k in range(7):\n",
        "  a,b = precision_test_data[k]\n",
        "  a = a.to(device)\n",
        "  a = a.float()\n",
        "  test_data2.append(UnPoinDeRupture(fct,(a,b),e,2, 8))\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "for a,b,c in test_data2:\n",
        "  v,w,z = a\n",
        "  #z = z.cpu().reshape((3,224,224))\n",
        "  s = torchvision.utils.make_grid(z.cpu())\n",
        "  s = s.numpy().transpose((1, 2, 0))\n",
        "  s = std * s + mean\n",
        "  s = np.clip(s, 0, 1)\n",
        "\n",
        "  #v = v.cpu().reshape((3,224,224))\n",
        "  t = torchvision.utils.make_grid(v.cpu())\n",
        "  t = t.numpy().transpose((1, 2, 0))\n",
        "  t = std * t + mean\n",
        "  t = np.clip(t, 0, 1)\n",
        "\n",
        "  h = (z-v)\n",
        "  #h = h.cpu().reshape((3,224,224))\n",
        "  r = torchvision.utils.make_grid(h.cpu())\n",
        "  r = r.numpy().transpose((1, 2, 0))\n",
        "  r = std * r + mean\n",
        "  r = np.clip(r, 0, 1)\n",
        "\n",
        "  grid_data2[w] = (s,t,r,Aug(h,1000))"
      ],
      "metadata": {
        "id": "sHnJNm_upBjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0Xbgz5blecr"
      },
      "outputs": [],
      "source": [
        "classif2= [[],[],[],[],[],[],[]]\n",
        "for a,b,c in test_data2:\n",
        "  with torch.no_grad():\n",
        "    u = torch.clone(a[-1])\n",
        "    v = torch.clone(a[0])\n",
        "    pred = model152(torch.reshape(u,(1,3, 224, 224)).to(device))\n",
        "    fred = model152(torch.reshape(v,(1,3, 224, 224)).to(device))\n",
        "    res = torch.argmax(pred).item()\n",
        "    ser = torch.argmax(fred).item()\n",
        "    classif2[res].append((res,ser))\n",
        "    #print(\"ASM\")\n",
        "    #print(c)\n",
        "    #print(\"Euc\")\n",
        "    #print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh-yFOetyu3T"
      },
      "outputs": [],
      "source": [
        "for j in range(7):\n",
        "  print(classif2[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM0drZuzjTwD"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cbook\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "\n",
        "imgs = grid_data2\n",
        "\n",
        "\n",
        "\n",
        "def demo_grid():\n",
        "\n",
        "    fig, axs = plt.subplots(4,7,figsize=(21,12),sharey=True)\n",
        "\n",
        "    l = [\"A\",\"B\",\"B-A\",\"exp(a*(B-A)) -1\"]\n",
        "\n",
        "    for i in range(4):\n",
        "      for k in range(7):\n",
        "\n",
        "        axs[i,k].imshow(grid_data2[k][i])\n",
        "        #axs[i,k].set_axis_off()\n",
        "        axs[i,k].set(xticks=[], yticks=[])\n",
        "        if i ==0:\n",
        "          axs[i, k].set(xlabel='A'+' classified as '+str(classe_names[classif2[k][0][0]]))\n",
        "        elif i ==1:\n",
        "          axs[i, k].set(xlabel='B'+' classified as '+str(classe_names[classif2[k][0][1]]))\n",
        "        elif i ==2:\n",
        "          axs[i, k].set(xlabel='B-A')\n",
        "        elif i ==3:\n",
        "          axs[i, k].set(xlabel='Saturated (B-A)')\n",
        "\n",
        "\n",
        "#fig = plt.figure(figsize=(120, 80))\n",
        "\n",
        "demo_grid()\n",
        "plt.savefig(\"Grille de comapraison saturation exp(abs) ResNet152\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E22yML9hmB9v"
      },
      "outputs": [],
      "source": [
        "\n",
        "demo_grid()\n",
        "plt.savefig(\"Grille de comapraison saturation exp(abs) ResNet152\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}