{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbjZJEqE9YHf4BwN6W6pg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOMBOU12/Marius/blob/main/Pr%C3%A9diction_conforme_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Projet : Classification et  Prédiction conforme**\n",
        "Le jeu de données **CIFAR-10** contient 60 000 images en couleur de taille 32x32. Ces images représentent des objets appartenant à 10 classes :\n",
        "\n",
        "*   avion\n",
        "*   automobile\n",
        "*   oiseau\n",
        "*   chat\n",
        "*   cerf\n",
        "*   chien\n",
        "*   grenouille\n",
        "*   cheval\n",
        "*   bateau\n",
        "*   camion\n",
        "\n",
        "Le jeu de données d'entraînement contient 50 000 images d'entraînement, soit 5 000 images par classe. Le jeu de test contient 10 000 images de test, soit 1 000 images par classe."
      ],
      "metadata": {
        "id": "TzA4AfATQeoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pourquoi ce jeu de donnée ?**\n",
        "\n",
        "CIFAR-10 comme jeu de données est un bon point de départ pour entraîner et tester des Convolutional Neural Networks (CNN), car il n'est pas trop volumineux mais suffisamment varié pour évaluer la performance d'un modèle."
      ],
      "metadata": {
        "id": "lcDlG89ZlEqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des données et statistiques simples**\n",
        "\n",
        "Tu dois dire pourquoi tu choisis ce jeu de donnée. Tu dois également faire de la regression linéaire sur ce jeu de donnée et dire si ça marche ou pas et pourquoi. Vu que tu as une CNN tu peux peut être penser faire de la CV+,  pour faire de la prédiction conforme. Il semble que la SCP serait judicieux"
      ],
      "metadata": {
        "id": "m3GUMGrrRuv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Charger les données CIFAR-10\n",
        "(X_full, y_full), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Diviser les données en trois ensembles : entraînement, calibration et test\n",
        "X_train, X_calibration, y_train, y_calibration = train_test_split(X_full, y_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalisation des données\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_calibration = X_calibration.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "XRZhWM4FFXl7",
        "outputId": "280b1700-a59b-4731-e9e7-752eec99af08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On entraînne le modèle"
      ],
      "metadata": {
        "id": "whLFB4YGfSli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Entraîner le modèle sur l'ensemble d'entraînement\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Prédire sur l'ensemble de calibration\n",
        "y_pred_calibration = model.predict(X_calibration)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3z7fP0_FKMb",
        "outputId": "c14fc2da-ae00-4d3c-a774-47367fe49c0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 86ms/step - accuracy: 0.3312 - loss: 1.8235 - val_accuracy: 0.4980 - val_loss: 1.4141\n",
            "Epoch 2/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 82ms/step - accuracy: 0.5469 - loss: 1.2931 - val_accuracy: 0.5935 - val_loss: 1.1827\n",
            "Epoch 3/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 101ms/step - accuracy: 0.6182 - loss: 1.1028 - val_accuracy: 0.6148 - val_loss: 1.0842\n",
            "Epoch 4/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 82ms/step - accuracy: 0.6476 - loss: 1.0121 - val_accuracy: 0.6275 - val_loss: 1.0474\n",
            "Epoch 5/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 88ms/step - accuracy: 0.6796 - loss: 0.9274 - val_accuracy: 0.6375 - val_loss: 1.0359\n",
            "Epoch 6/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 85ms/step - accuracy: 0.6954 - loss: 0.8880 - val_accuracy: 0.6390 - val_loss: 1.0288\n",
            "Epoch 7/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 88ms/step - accuracy: 0.7086 - loss: 0.8349 - val_accuracy: 0.6718 - val_loss: 0.9620\n",
            "Epoch 8/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 82ms/step - accuracy: 0.7296 - loss: 0.7774 - val_accuracy: 0.6662 - val_loss: 0.9727\n",
            "Epoch 9/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 84ms/step - accuracy: 0.7455 - loss: 0.7352 - val_accuracy: 0.6622 - val_loss: 0.9850\n",
            "Epoch 10/10\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 82ms/step - accuracy: 0.7619 - loss: 0.7001 - val_accuracy: 0.6755 - val_loss: 0.9572\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **La prédiction conforme**\n",
        "\n",
        "On fait une SCP parceque nous avons beaucoup de données et on cherche à ajuster la distribution des prédictions et fournir un intervalle de confiance pour les prédictions sur les nouvelles données"
      ],
      "metadata": {
        "id": "xXmNQwr-jKjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Calcul des scores de non-conformité sur l'ensemble de calibration"
      ],
      "metadata": {
        "id": "zxuolH9PR5wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Prédictions de calibration\n",
        "y_pred_calibration_probs = model.predict(X_calibration)\n",
        "\n",
        "# Extraire les probabilités de la vraie classe\n",
        "true_class_probs = np.array([y_pred_calibration_probs[i, y_calibration[i]] for i in range(len(y_calibration))])\n",
        "\n",
        "# Calculer les scores de non-conformité\n",
        "non_conformity_scores = 1 - true_class_probs\n"
      ],
      "metadata": {
        "id": "6cn42vJ3R4oJ",
        "outputId": "b0c2cf5d-7434-433b-d038-73ae305e830a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. On fixe le niveau de couverture souhaité"
      ],
      "metadata": {
        "id": "wAOQ6UncSmBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixer le niveau de couverture à 90%\n",
        "alpha = 0.1\n",
        "quantile_threshold = np.quantile(non_conformity_scores, 1 - alpha)"
      ],
      "metadata": {
        "id": "FIwvGeYzSwlC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. On Applique le seuil de non-conformité sur les nouvelles prédictions"
      ],
      "metadata": {
        "id": "Osmdz_-fS04z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédictions sur l'ensemble de test\n",
        "y_pred_test_probs = model.predict(X_test)\n",
        "\n",
        "# Construire l'ensemble prédictif pour chaque échantillon de test\n",
        "prediction_sets = []\n",
        "for i in range(len(X_test)):\n",
        "    prediction_set = np.where(y_pred_test_probs[i] >= 1 - quantile_threshold)[0]\n",
        "    prediction_sets.append(prediction_set)\n"
      ],
      "metadata": {
        "id": "BCfhBqN8S-57",
        "outputId": "5df862b3-90c8-4fce-f1c9-f0e3b59fc1ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. On calcul la couverture et la taille moyenne des ensembles prédictifs"
      ],
      "metadata": {
        "id": "tYgaZPyETE8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer la couverture\n",
        "correct_cover = [y_test[i] in prediction_sets[i] for i in range(len(y_test))]\n",
        "coverage = np.mean(correct_cover)\n",
        "\n",
        "# Calculer la taille moyenne des ensembles prédictifs\n",
        "average_set_size = np.mean([len(prediction_set) for prediction_set in prediction_sets])\n",
        "\n",
        "print(f\"Couverture : {coverage * 100:.2f}%\")\n",
        "print(f\"Taille moyenne des ensembles prédictifs : {average_set_size:.2f}\")\n"
      ],
      "metadata": {
        "id": "Lggxu4t2TJDn",
        "outputId": "e42564f9-2bc5-420f-bc31-310e6151efff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couverture : 89.21%\n",
            "Taille moyenne des ensembles prédictifs : 2.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Couverture de 89,21%**: Cela signifie que, dans environ 9 cas sur 10, la véritable classe est incluse dans l'ensemble prédictif proposé, ce qui est proche de l'objectif de 90%.\n",
        "*   La **taille moyenne des ensembles prédictifs** indique le nombre moyen de classes incluses dans l'ensemble proposé pour chaque prédiction. Ici, chaque prédiction conforme propose en moyenne 2,13 classes, ce qui signifie que le modèle fournit un ensemble de 2 ou 3 classes en moyenne pour chaque image testée.\n",
        "\n"
      ],
      "metadata": {
        "id": "1lbYskELeiKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression Linéaire**"
      ],
      "metadata": {
        "id": "VTILKP79TMmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Charger les données CIFAR-10\n",
        "(X_full, y_full), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Redimensionner les données pour les rendre compatibles avec la régression linéaire\n",
        "# Convertir les images de 32x32x3 en vecteurs de 32*32*3 = 3072 dimensions\n",
        "X_full_flat = X_full.reshape((X_full.shape[0], -1))\n",
        "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de calibration\n",
        "X_train, X_calibration, y_train, y_calibration = train_test_split(X_full_flat, y_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normaliser les données pour que les pixels soient compris entre 0 et 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_calibration = X_calibration.astype('float32') / 255.0\n",
        "X_test_flat = X_test_flat.astype('float32') / 255.0\n",
        "\n",
        "# Appliquer une régression linéaire\n",
        "model = LinearRegression()\n",
        "\n",
        "# Entraîner le modèle sur l'ensemble d'entraînement\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred = model.predict(X_test_flat)\n",
        "\n",
        "# Calculer l'erreur quadratique moyenne (MSE) et le R² pour évaluer les performances\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Erreur quadratique moyenne (MSE) : {mse}\")\n",
        "print(f\"Coefficient de détermination (R²) : {r2}\")\n"
      ],
      "metadata": {
        "id": "srZVKWC0U5Ek",
        "outputId": "e6c57aec-b694-4112-8e16-65277ce009e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erreur quadratique moyenne (MSE) : 8.177422523498535\n",
            "Coefficient de détermination (R²) : 0.008797228336334229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une MSE de 8.18 signifie que, en moyenne, les prédictions sont à une distance quadratique de 8.18 des vraies valeurs de classe. Puisque les classes vont de 0 à 9, cela montre que le modèle fait des erreurs assez importantes.\n",
        "\n",
        "La **régression linéaire** n'est pas un modèle adapté pour ce type de données, car elle suppose une relation linéaire continue entre les pixels et les classes. Or, dans CIFAR-10, les classes sont des labels discrets (catégories d'objets comme des chats, avions, etc.), et il n'existe pas de relation continue ou ordinale entre elles."
      ],
      "metadata": {
        "id": "RyF85PpOdgzz"
      }
    }
  ]
}